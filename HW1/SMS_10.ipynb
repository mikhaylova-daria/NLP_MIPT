{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат на cv: 0.9724\n",
    "\n",
    "Модель: LinearSVC()\n",
    "\n",
    "Признаки: \n",
    " - 1535 шт CountVectorizer(analyzer='char_wb', ngram_range=(2, 4)) + отбор ExtraTreesClassifier\n",
    " - CountVectorizer(ngram_range=(1, 2)) на тексте, полученном из shape слов (функция shape_word()) \n",
    " - количество предложений в сообщении\n",
    " - количество ключевых спам-слов в сообщении ('£', 'http','www.', '.com', 'prize', 'FREE', '18+', ...) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = open('SMSSpamCollection.txt')\n",
    "raw_corpus = []\n",
    "for i, line in enumerate(text_file):\n",
    "    raw_corpus.append([line.split()[0].strip(), line.split('\\t', 1 )[1].strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "import string\n",
    "alp_lower = list(string.ascii_lowercase)\n",
    "alp_upper = list(string.ascii_uppercase)\n",
    "numbers = list(string.digits)\n",
    "punkt=['+', '.', '?', '!', '/', '-', '=', ',', '&', u'£']\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# переводим строчные буквы в x, заглавные в X, цифры в 0 и схлопываем подряд идущие дубли\n",
    "def shape_word(word):\n",
    "    new_word = '1'\n",
    "    for ch in word:\n",
    "        if ch in alp_lower and new_word[-1] != 'x':\n",
    "            new_word += 'x'\n",
    "        elif ch in alp_lower and new_word[-1] == 'x':\n",
    "            a=[]\n",
    "        elif ch in alp_upper and new_word[-1] != 'X':\n",
    "            new_word += 'X'\n",
    "        elif ch in alp_upper and new_word[-1] == 'X':\n",
    "            a=[]\n",
    "        elif ch in numbers and new_word[-1] != '0':\n",
    "            new_word +='0'\n",
    "        elif ch in numbers and new_word[-1] == '0':\n",
    "            a=[]\n",
    "        elif ch in punkt:\n",
    "            new_word += ch\n",
    "        else:\n",
    "            new_word += '_'\n",
    "    return new_word[1:]\n",
    "\n",
    "\n",
    "def tok(sentense):\n",
    "    return [shape_word(word)for word in sentense.split()]\n",
    "\n",
    "#количество цифр в сообещении\n",
    "def count_number(text):\n",
    "    count = 0\n",
    "    for ch in text:\n",
    "        if ch in numbers:\n",
    "            count+=1\n",
    "    return [count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [raw_corpus[i][0]=='spam' for i in range(len(raw_corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(2, 4))\n",
    "vectorizer_mask = CountVectorizer(tokenizer=tok, ngram_range=(1, 2))\n",
    "sent_length = [[len(nltk.sent_tokenize(raw_corpus[i][1].decode('utf-8')))] for i in range(len(raw_corpus))]\n",
    "X = [vectorizer.fit_transform([raw_corpus[i][1] for i in range(len(raw_corpus))]).toarray(), vectorizer_mask.fit_transform([raw_corpus[i][1] for i in range(len(raw_corpus))]).toarray(), sent_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#метки спама\n",
    "spam_words = ['£', 'http','www.', '.com', \n",
    "              'prize', '.net', 'only', 'free', 'now', 'call', 'yes', 'no', 'txt'\n",
    "              'sms', 'award', 'go', 'stop', '18+', '16+']\n",
    "X_spam_labels = []\n",
    "for x in raw_corpus:\n",
    "    spam_labels = []\n",
    "    for word in spam_words:\n",
    "        spam_labels.append(x[1].lower().find(word) != -1)\n",
    "    X_spam_labels.append([sum(spam_labels)])\n",
    "X.append(X_spam_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.append([count_number(raw_corpus[i][1]) for i in range(len(raw_corpus))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizerTfV = TfidfVectorizer()\n",
    "X.append(vectorizerTfV.fit_transform([raw_corpus[i][1] for i in range(len(raw_corpus))]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.append([count_number(raw_corpus[i][1]) for i in range(len(raw_corpus))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.966107861528\n",
      "0.965426614778\n",
      "0.966826252333\n",
      "0.96424601158\n",
      "0.964906462241\n"
     ]
    }
   ],
   "source": [
    "clSVC = LinearSVC()\n",
    "X_test = X[0]\n",
    "for i in range(1, 6):\n",
    "    X_test = np.hstack((X_test, X[i]))\n",
    "    scores = cross_val_score(clSVC, X_test, Y, cv=10, scoring='f1')\n",
    "    print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/physteshka/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#отбор признаков, полученных TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ets = ExtraTreesClassifier(n_estimators=70, max_features=4000, bootstrap=True, n_jobs=-1)\n",
    "X.append(ets.fit_transform(X[5], Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/physteshka/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#отбор признков, полученных CountVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ets = ExtraTreesClassifier(n_estimators=70, max_features=4000, bootstrap=True, n_jobs=-1)\n",
    "X.append(ets.fit_transform(X[0], Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971710466105\n",
      "0.971710466105\n",
      "0.972449164027\n",
      "0.972449164027\n",
      "0.971889802505\n",
      "0.971889802505\n"
     ]
    }
   ],
   "source": [
    "X_test = X[8]\n",
    "features_number = [1, 2, 3, 7, 4, 6]\n",
    "for i in features_number:\n",
    "    X_test = np.hstack((X_test, X[i]))\n",
    "    scores = cross_val_score(clSVC, X_test, Y, cv=10, scoring='f1')\n",
    "    print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/physteshka/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "ets = ExtraTreesClassifier(n_estimators=100, max_features=4000, bootstrap=True, n_jobs=-1)\n",
    "X.append(ets.fit_transform(X_test, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969000581194\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clSVC, X[-1], Y, cv=10, scoring='f1')\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.969645000348\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators=400, bootstrap=True, n_jobs=-1)\n",
    "scores = cross_val_score(etc, X[-1], Y, cv=10, scoring='f1')\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
